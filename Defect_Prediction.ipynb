{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'data_io'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/wsuser/ipykernel_154/907076112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefectDataSetLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorFlowNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_LAYER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_io'"
                    ]
                }
            ],
            "source": "import argparse\nimport logging\nfrom data_io.test_data import DefectDataSetLoader, DataSet\nfrom prediction.tf_model import TensorFlowNet, TF_LAYER\nimport numpy as np\n\ndef create_loggers():\n    # setup logging\n    logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', filename='run.log', filemode='w', level=logging.DEBUG)\n\n    # create loggers\n    logger_io = logging.getLogger('io')\n    logger_io.setLevel(logging.DEBUG)\n\n    logger_prediction = logging.getLogger('prediction')\n    logger_prediction.setLevel(logging.DEBUG)\n\n    # create console handler and set level to debug\n    ch_pred = logging.StreamHandler()\n    ch_pred.setLevel(logging.INFO)\n\n    ch_io = logging.StreamHandler()\n    ch_io.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to ch\n    ch_io.setFormatter(formatter)\n    ch_pred.setFormatter(formatter)\n\n    # add ch to logger\n    logger_io.addHandler(ch_io)\n    logger_prediction.addHandler(ch_pred)\n\ncreate_loggers()\n\nparser = argparse.ArgumentParser()\nparser.add_argument('-p', '--sourcepath', help='Root path for the source files.', required=False, default='C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/apache-ant-1.7.0-src/apache-ant-1.7.0/src/main')\nparser.add_argument('-b', '--bugdatapath', help='Path to the csv bug data sheet.', required=False, default='C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/ant-1.7.csv')\nparser.add_argument('-s', '--save', help='Path to the location to save the model data in.', required=False, default='C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/save/')\nparser.add_argument('-lt', '--loadtestdata', help='Path to pickeled feature vector.', required=False)\nparser.add_argument('-im', '--buginfomapping', help='Row index of the class info inside the bug info csv.', required=False, default=2)\nparser.add_argument('-bn', '--bugnumbermapping', help='Row index of the number_of_bugs inside the bug info csv.', required=False, default=23)\nparser.add_argument('-st', '--savetestdata', help='Save test data or not.', action='store_true')\nargs = parser.parse_args()\ntest_data_path = args.sourcepath\nbug_data_path = args.bugdatapath\nload_test_data = args.loadtestdata\nsave_data_set = args.savetestdata\nsave_data_set = True\n\n\ntest_data_path = [\n    #'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/jakarta-ant-1.3-src/src/main',\n    #'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/jakarta-ant-1.4-src/src/main',\n    #'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/jakarta-ant-1.5-src/src/main',\n    'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/apache-ant-1.6.0-src/src/main', \n    'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/apache-ant-1.7.0-src/src/main']\n\nbug_data_path = [\n    #'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/ant-1.3.csv',\n    #'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/ant-1.4.csv',\n    #'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/ant-1.5.csv',\n    'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/ant-1.6.csv', \n    'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/ant-1.7.csv']\n\n\nload_test_data = 'C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/'\n\n\ndata_set_loader = DefectDataSetLoader(test_data_path, bug_data_path, source_files_extension='.java', one_hot=False, binary_class_labels=True)\n\nif load_test_data is None:\n    data_set_loader.initialize(args.buginfomapping, args.bugnumbermapping) \nelse:\n    data_set_loader.load_features(load_test_data, name='feature_vector.pickle')\n\nif save_data_set:\n    data_set_loader.save_features('C:/Users/felix/OneDrive/Studium/Studium/2. Semester/Seminar/Project/Training/')\n\n#X_train, X_test, y_train, y_test = data_set_loader.get_test_train_split()\n# create test sets\n#train = DataSet(X_train, y_train, 'Train', one_hot=False)\n#test = DataSet(X_test, y_test, 'Test', one_hot=False)\n\n\nX, y = data_set_loader.get_project_split()\n\n# combine data from ant 1.4 to 1.6\n#X_train = np.concatenate((X[0], X[1], X[2]), axis=0)\n#y_train = np.concatenate((y[0], y[1], y[2]), axis=0)\n\ntrain = DataSet(X[-2], y[-2], 'Train', one_hot=True)\ntest = DataSet(X[-1], y[-1], 'Test', one_hot=True)\n\nnet = TensorFlowNet(\n    train_data_set=train,\n    test_data_set=test, \n    num_classes=data_set_loader.num_classes, \n    input_shape=[train.feature_shape[1]], # Feature Shape is (Num_Samples, Feature_dim) -> we only need Feature_dim\n    targets_shape=[-1, 2], # one hot\n    input_is_image=False,\n    batch_size=100, \n    initial_learning_rate=1e-4, \n    architecture_shape=[\n        (TF_LAYER.Dense, 'hidden1', 128),         \n        (TF_LAYER.Dense, 'hidden2', 128),\n        (TF_LAYER.Dense, 'hidden3', 16),\n        (TF_LAYER.Dropout, 'dropout1', 0.4)],\n    max_epochs=500,\n    model_name='Demo',\n    calculate_f1_score=True,\n    num_epochs_per_decay=90\n    )\nnet.run_training()\nnum_prediction_tests = 10\nX, y = test.get_random_elements(num_prediction_tests)\n\nfor i in range(num_prediction_tests):\n    y_hat, prob = net.predict(X[i])\n    print('Y: {0} - Y predicted: {1} ({2:.2f})'.format(y[i], y_hat, prob))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}